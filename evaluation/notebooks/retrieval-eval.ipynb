{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from llm_requests import *\n",
    "from pinecone_db import *\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['OPENAI_API_KEY'] = os.getenv('OPENAI_API_KEY')\n",
    "os.environ['TOKENIZERS_PARALLELISM'] = \"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\ufeffAnimation movie toys move into new house, jealous toy sheriff, space ranger action figure, sadistic neighbor, mutant toys, Pizza Planet, Christmas gift-opening scene',\n",
       " 'Documentary martial arts dance rituals, war dances, sword dances, cultural significance, martial arts performance with music',\n",
       " 'Dark comedy series based on graphic novel, teen psychopath road trip, rebel adventure, star-crossed teenagers']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('TestQueries.txt', 'r', encoding='utf-8') as f:\n",
    "    search_queries = f.readlines()\n",
    "    search_queries = list(map(lambda q: q.strip(), search_queries))\n",
    "\n",
    "search_queries[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "def gpt_evaluate(search_query: str, search_results: list, k: int):\n",
    "    prompt = \"\"\n",
    "    cnt = 1\n",
    "    for res in search_results:\n",
    "        title, description = res['title'], res['description']\n",
    "        if title not in prompt and cnt <= k and len(description) > 20:\n",
    "            prompt += f\"{cnt}. Title: {title}\\nDescription: {description}\\n\\n\"\n",
    "            cnt += 1\n",
    "    prompt = prompt.strip()\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a fair evaluator of movie search system.\"\n",
    "         \"You will be provided a search query and search results with movies descriptions. \"\n",
    "         \"Your task is for each movie to return either 0 or 1 to indicate whether movie is relevant \"\n",
    "         \"and good reccomendation based on provided search query or not. Output format should be Python list \"\n",
    "         \"of 0s and 1s of length returned movies.\"},\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"\"\"\n",
    "Search query: {search_query}\\n\\nOutput movies:\n",
    "{prompt}\n",
    "Provide evaluation list of length {k}.\n",
    "\"\"\"\n",
    "            },\n",
    "        ]\n",
    "    )\n",
    "    response_str = response.choices[0].message.content\n",
    "    start, end = response_str.find('['), response_str.find(']')\n",
    "    return ast.literal_eval(response_str[start:end+1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_metadata(query: str) -> dict:\n",
    "    url = f\"http://localhost:8085/extract_metadata\"\n",
    "    body = {\n",
    "        \"query\": query,\n",
    "        \"parameters\": {}\n",
    "    }\n",
    "    try:\n",
    "        response = requests.post(url, json=body)\n",
    "        if response.status_code == 200:\n",
    "            return response.json()\n",
    "        return {\"error\":\n",
    "                f\"Request failed with status code {response.status_code}\\nAPI URL: {url}\"\n",
    "                }\n",
    "    except Exception as e:\n",
    "        return {\"error\": f\"An error occurred: {str(e)}\"}\n",
    "\n",
    "def search_movies(\n",
    "        chunking_strategy: str,\n",
    "        embedding_model: str,\n",
    "        query: str,\n",
    "        metadata: dict,\n",
    "        k: int,\n",
    "        min_similarity_score: float) -> dict:\n",
    "    url = f\"http://localhost:8080/search_movies\"\n",
    "    body = {\n",
    "        \"chunking_strategy\": chunking_strategy,\n",
    "        \"embedding_model\": embedding_model,\n",
    "        \"query\": query,\n",
    "        \"metadata\": metadata,\n",
    "        \"k\": k,\n",
    "        \"min_similarity_score\": min_similarity_score\n",
    "    }\n",
    "    try:\n",
    "        response = requests.post(url, json=body)\n",
    "        if response.status_code == 200:\n",
    "            return response.json()\n",
    "        return {\"error\":\n",
    "                f\"Request failed with status code {response.status_code}\"\n",
    "                }\n",
    "    except Exception as e:\n",
    "        return {\"error\": f\"An error occurred: {str(e)}\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHUNKING_STRATEGIES = [\n",
    "    'fixed-size-splitter',\n",
    "    'recursive-splitter',\n",
    "    'semantic-splitter'\n",
    "    ]\n",
    "EMBEDDING_MODELS = [\n",
    "    'all-MiniLM-L6-v2',\n",
    "    'bert-base-nli-mean-tokens',\n",
    "    'gtr-t5-base'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [01:30<00:00, 45.17s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chunking_strategy</th>\n",
       "      <th>embedding_model</th>\n",
       "      <th>search_query</th>\n",
       "      <th>extracted_metadata</th>\n",
       "      <th>scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fixed-size-splitter</td>\n",
       "      <td>all-MiniLM-L6-v2</td>\n",
       "      <td>﻿Animation movie toys move into new house, jea...</td>\n",
       "      <td>{'title': 'Toy Story', 'genre': 'animation', '...</td>\n",
       "      <td>[1, 1, 0, 1, 0, 0, 1, 1, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fixed-size-splitter</td>\n",
       "      <td>bert-base-nli-mean-tokens</td>\n",
       "      <td>﻿Animation movie toys move into new house, jea...</td>\n",
       "      <td>{'title': 'Toy Story', 'genre': 'animation', '...</td>\n",
       "      <td>[1, 1, 0, 1, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fixed-size-splitter</td>\n",
       "      <td>gtr-t5-base</td>\n",
       "      <td>﻿Animation movie toys move into new house, jea...</td>\n",
       "      <td>{'title': 'Toy Story', 'genre': 'animation', '...</td>\n",
       "      <td>[1, 1, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>recursive-splitter</td>\n",
       "      <td>all-MiniLM-L6-v2</td>\n",
       "      <td>﻿Animation movie toys move into new house, jea...</td>\n",
       "      <td>{'title': 'Toy Story', 'genre': 'animation', '...</td>\n",
       "      <td>[1, 0, 1, 1, 0, 0, 1, 0, 1, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>recursive-splitter</td>\n",
       "      <td>bert-base-nli-mean-tokens</td>\n",
       "      <td>﻿Animation movie toys move into new house, jea...</td>\n",
       "      <td>{'title': 'Toy Story', 'genre': 'animation', '...</td>\n",
       "      <td>[1, 1, 1, 0, 0, 0, 0, 0, 0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>semantic-splitter</td>\n",
       "      <td>bert-base-nli-mean-tokens</td>\n",
       "      <td>British crime drama centered around a detectiv...</td>\n",
       "      <td>{'title': '', 'genre': 'british shows', 'min_y...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>semantic-splitter</td>\n",
       "      <td>gtr-t5-base</td>\n",
       "      <td>British crime drama centered around a detectiv...</td>\n",
       "      <td>{'title': '', 'genre': 'british shows', 'min_y...</td>\n",
       "      <td>[1, 1, 0, 1, 1, 1, 0, 1, 1, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>semantic-splitter</td>\n",
       "      <td>all-MiniLM-L6-v2</td>\n",
       "      <td>Spanish-language shows telenovelas, Latin Amer...</td>\n",
       "      <td>{'title': '', 'genre': 'Spanish-language shows...</td>\n",
       "      <td>[1, 1, 0, 1, 0, 1, 0, 1, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>semantic-splitter</td>\n",
       "      <td>bert-base-nli-mean-tokens</td>\n",
       "      <td>Spanish-language shows telenovelas, Latin Amer...</td>\n",
       "      <td>{'title': '', 'genre': 'Spanish-language shows...</td>\n",
       "      <td>[1, 1, 1, 0, 1, 0, 1, 1, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>semantic-splitter</td>\n",
       "      <td>gtr-t5-base</td>\n",
       "      <td>Spanish-language shows telenovelas, Latin Amer...</td>\n",
       "      <td>{'title': '', 'genre': 'Spanish-language shows...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>900 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      chunking_strategy            embedding_model  \\\n",
       "0   fixed-size-splitter           all-MiniLM-L6-v2   \n",
       "1   fixed-size-splitter  bert-base-nli-mean-tokens   \n",
       "2   fixed-size-splitter                gtr-t5-base   \n",
       "3    recursive-splitter           all-MiniLM-L6-v2   \n",
       "4    recursive-splitter  bert-base-nli-mean-tokens   \n",
       "..                  ...                        ...   \n",
       "0     semantic-splitter  bert-base-nli-mean-tokens   \n",
       "0     semantic-splitter                gtr-t5-base   \n",
       "0     semantic-splitter           all-MiniLM-L6-v2   \n",
       "0     semantic-splitter  bert-base-nli-mean-tokens   \n",
       "0     semantic-splitter                gtr-t5-base   \n",
       "\n",
       "                                         search_query  \\\n",
       "0   ﻿Animation movie toys move into new house, jea...   \n",
       "1   ﻿Animation movie toys move into new house, jea...   \n",
       "2   ﻿Animation movie toys move into new house, jea...   \n",
       "3   ﻿Animation movie toys move into new house, jea...   \n",
       "4   ﻿Animation movie toys move into new house, jea...   \n",
       "..                                                ...   \n",
       "0   British crime drama centered around a detectiv...   \n",
       "0   British crime drama centered around a detectiv...   \n",
       "0   Spanish-language shows telenovelas, Latin Amer...   \n",
       "0   Spanish-language shows telenovelas, Latin Amer...   \n",
       "0   Spanish-language shows telenovelas, Latin Amer...   \n",
       "\n",
       "                                   extracted_metadata  \\\n",
       "0   {'title': 'Toy Story', 'genre': 'animation', '...   \n",
       "1   {'title': 'Toy Story', 'genre': 'animation', '...   \n",
       "2   {'title': 'Toy Story', 'genre': 'animation', '...   \n",
       "3   {'title': 'Toy Story', 'genre': 'animation', '...   \n",
       "4   {'title': 'Toy Story', 'genre': 'animation', '...   \n",
       "..                                                ...   \n",
       "0   {'title': '', 'genre': 'british shows', 'min_y...   \n",
       "0   {'title': '', 'genre': 'british shows', 'min_y...   \n",
       "0   {'title': '', 'genre': 'Spanish-language shows...   \n",
       "0   {'title': '', 'genre': 'Spanish-language shows...   \n",
       "0   {'title': '', 'genre': 'Spanish-language shows...   \n",
       "\n",
       "                            scores  \n",
       "0   [1, 1, 0, 1, 0, 0, 1, 1, 0, 0]  \n",
       "1   [1, 1, 0, 1, 0, 0, 0, 0, 0, 0]  \n",
       "2   [1, 1, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "3   [1, 0, 1, 1, 0, 0, 1, 0, 1, 1]  \n",
       "4   [1, 1, 1, 0, 0, 0, 0, 0, 0, 1]  \n",
       "..                             ...  \n",
       "0   [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]  \n",
       "0   [1, 1, 0, 1, 1, 1, 0, 1, 1, 1]  \n",
       "0   [1, 1, 0, 1, 0, 1, 0, 1, 0, 0]  \n",
       "0   [1, 1, 1, 0, 1, 0, 1, 1, 0, 0]  \n",
       "0   [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]  \n",
       "\n",
       "[900 rows x 5 columns]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def evaluate_retrieval(search_queries: list, k: int, search: str):\n",
    "    MAX_ATTEMPTS = 3\n",
    "    evaluation_results = pd.DataFrame(\n",
    "        {\n",
    "            'chunking_strategy': [],\n",
    "            'embedding_model': [],\n",
    "            'search_query': [],\n",
    "            'extracted_metadata': [],\n",
    "            'scores': []\n",
    "        }\n",
    "    )\n",
    "\n",
    "    for i, query in zip(tqdm(range(len(search_queries))), search_queries):\n",
    "        attempt = 0\n",
    "        success = False\n",
    "        while not success and attempt < MAX_ATTEMPTS:\n",
    "            try:\n",
    "                if search == 'hybrid':\n",
    "                    metadata = extract_metadata(query)\n",
    "                    metadata['generated_response'] = ast.literal_eval(metadata['generated_response'])\n",
    "                    metadata = metadata['generated_response']\n",
    "                else:\n",
    "                    metadata = {}\n",
    "                for chunking_strategy in CHUNKING_STRATEGIES:\n",
    "                    for embedding_model in EMBEDDING_MODELS:\n",
    "                        search_results = search_movies(\n",
    "                            chunking_strategy=chunking_strategy,\n",
    "                            embedding_model=embedding_model,\n",
    "                            query=query,\n",
    "                            metadata=metadata,\n",
    "                            k=k,\n",
    "                            min_similarity_score=0\n",
    "                        )['search_results']\n",
    "\n",
    "                        scores = gpt_evaluate(query, search_results, k)\n",
    "                        evaluation_results = pd.concat([evaluation_results, pd.DataFrame(\n",
    "                                {\n",
    "                                    'chunking_strategy': [chunking_strategy],\n",
    "                                    'embedding_model': [embedding_model],\n",
    "                                    'search_query': [query],\n",
    "                                    'extracted_metadata': [metadata],\n",
    "                                    'scores': [scores]\n",
    "                                    }\n",
    "                        )])\n",
    "                        success = True\n",
    "                        evaluation_results.to_csv(f'retrieval_validation/gpt_evaluations_{search}_search.csv', index=False)\n",
    "            except:\n",
    "                attempt += 1\n",
    "\n",
    "    return evaluation_results\n",
    "\n",
    "evaluation_results = evaluate_retrieval(search_queries=search_queries, k=10, search='hybrid')\n",
    "evaluation_results.to_csv('retrieval_validation/gpt_evaluations_hybrid_search.csv', index=False)\n",
    "evaluation_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [17:04<00:00, 10.25s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chunking_strategy</th>\n",
       "      <th>embedding_model</th>\n",
       "      <th>search_query</th>\n",
       "      <th>extracted_metadata</th>\n",
       "      <th>scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fixed-size-splitter</td>\n",
       "      <td>all-MiniLM-L6-v2</td>\n",
       "      <td>﻿Animation movie toys move into new house, jea...</td>\n",
       "      <td>{}</td>\n",
       "      <td>[0, 1, 0, 0, 1, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fixed-size-splitter</td>\n",
       "      <td>bert-base-nli-mean-tokens</td>\n",
       "      <td>﻿Animation movie toys move into new house, jea...</td>\n",
       "      <td>{}</td>\n",
       "      <td>[1, 1, 0, 0, 1, 1, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fixed-size-splitter</td>\n",
       "      <td>gtr-t5-base</td>\n",
       "      <td>﻿Animation movie toys move into new house, jea...</td>\n",
       "      <td>{}</td>\n",
       "      <td>[1, 1, 0, 0, 0, 1, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>recursive-splitter</td>\n",
       "      <td>all-MiniLM-L6-v2</td>\n",
       "      <td>﻿Animation movie toys move into new house, jea...</td>\n",
       "      <td>{}</td>\n",
       "      <td>[1, 0, 1, 1, 1, 0, 0, 0, 0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>recursive-splitter</td>\n",
       "      <td>bert-base-nli-mean-tokens</td>\n",
       "      <td>﻿Animation movie toys move into new house, jea...</td>\n",
       "      <td>{}</td>\n",
       "      <td>[1, 1, 0, 1, 0, 0, 0, 0, 1, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>recursive-splitter</td>\n",
       "      <td>bert-base-nli-mean-tokens</td>\n",
       "      <td>Film-noir classic noir atmosphere, gritty crim...</td>\n",
       "      <td>{}</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>recursive-splitter</td>\n",
       "      <td>gtr-t5-base</td>\n",
       "      <td>Film-noir classic noir atmosphere, gritty crim...</td>\n",
       "      <td>{}</td>\n",
       "      <td>[0, 0, 1, 1, 0, 0, 0, 1, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>semantic-splitter</td>\n",
       "      <td>all-MiniLM-L6-v2</td>\n",
       "      <td>Film-noir classic noir atmosphere, gritty crim...</td>\n",
       "      <td>{}</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>semantic-splitter</td>\n",
       "      <td>bert-base-nli-mean-tokens</td>\n",
       "      <td>Film-noir classic noir atmosphere, gritty crim...</td>\n",
       "      <td>{}</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>semantic-splitter</td>\n",
       "      <td>gtr-t5-base</td>\n",
       "      <td>Film-noir classic noir atmosphere, gritty crim...</td>\n",
       "      <td>{}</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 1, 0, 1, 0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>896 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      chunking_strategy            embedding_model  \\\n",
       "0   fixed-size-splitter           all-MiniLM-L6-v2   \n",
       "0   fixed-size-splitter  bert-base-nli-mean-tokens   \n",
       "0   fixed-size-splitter                gtr-t5-base   \n",
       "0    recursive-splitter           all-MiniLM-L6-v2   \n",
       "0    recursive-splitter  bert-base-nli-mean-tokens   \n",
       "..                  ...                        ...   \n",
       "0    recursive-splitter  bert-base-nli-mean-tokens   \n",
       "0    recursive-splitter                gtr-t5-base   \n",
       "0     semantic-splitter           all-MiniLM-L6-v2   \n",
       "0     semantic-splitter  bert-base-nli-mean-tokens   \n",
       "0     semantic-splitter                gtr-t5-base   \n",
       "\n",
       "                                         search_query extracted_metadata  \\\n",
       "0   ﻿Animation movie toys move into new house, jea...                 {}   \n",
       "0   ﻿Animation movie toys move into new house, jea...                 {}   \n",
       "0   ﻿Animation movie toys move into new house, jea...                 {}   \n",
       "0   ﻿Animation movie toys move into new house, jea...                 {}   \n",
       "0   ﻿Animation movie toys move into new house, jea...                 {}   \n",
       "..                                                ...                ...   \n",
       "0   Film-noir classic noir atmosphere, gritty crim...                 {}   \n",
       "0   Film-noir classic noir atmosphere, gritty crim...                 {}   \n",
       "0   Film-noir classic noir atmosphere, gritty crim...                 {}   \n",
       "0   Film-noir classic noir atmosphere, gritty crim...                 {}   \n",
       "0   Film-noir classic noir atmosphere, gritty crim...                 {}   \n",
       "\n",
       "                            scores  \n",
       "0   [0, 1, 0, 0, 1, 0, 0, 0, 0, 0]  \n",
       "0   [1, 1, 0, 0, 1, 1, 0, 0, 0, 0]  \n",
       "0   [1, 1, 0, 0, 0, 1, 0, 0, 0, 0]  \n",
       "0   [1, 0, 1, 1, 1, 0, 0, 0, 0, 1]  \n",
       "0   [1, 1, 0, 1, 0, 0, 0, 0, 1, 0]  \n",
       "..                             ...  \n",
       "0   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "0   [0, 0, 1, 1, 0, 0, 0, 1, 0, 0]  \n",
       "0   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "0   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "0   [0, 0, 0, 0, 0, 0, 1, 0, 1, 0]  \n",
       "\n",
       "[896 rows x 5 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_results = evaluate_retrieval(search_queries=search_queries, k=10, search='vector')\n",
    "evaluation_results.to_csv('retrieval_validation/gpt_evaluations_vector_search.csv', index=False)\n",
    "evaluation_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_precision_at_k(evaluation_results: pd.DataFrame) -> float:\n",
    "    scores = []\n",
    "\n",
    "    for _, row in evaluation_results.iterrows():\n",
    "        score = row['scores']\n",
    "        precision = sum(score) / len(score)\n",
    "        scores.append(precision)\n",
    "    return round(np.mean(scores), 4)\n",
    "\n",
    "def compute_hit_rate(evaluation_results: pd.DataFrame) -> float:\n",
    "    scores = []\n",
    "\n",
    "    for _, row in evaluation_results.iterrows():\n",
    "        score = row['scores']\n",
    "        if 1 in score:\n",
    "            scores.append(1)\n",
    "        else:\n",
    "            scores.append(0)\n",
    "    return round(np.mean(scores), 4)\n",
    "\n",
    "def compute_ndcg(evaluation_results: pd.DataFrame) -> float:\n",
    "    scores = []\n",
    "\n",
    "    for _, row in evaluation_results.iterrows():\n",
    "        score = row['scores']\n",
    "        dcg = sum([s/np.log(i+2) for i, s in enumerate(score)])\n",
    "        idcg = sum([1/np.log(i+2) for i, s in enumerate(score)])\n",
    "        scores.append(dcg/idcg)\n",
    "    return round(np.mean(scores), 4)\n",
    "\n",
    "def compute_mrr(evaluation_results: pd.DataFrame) -> float:\n",
    "    scores = []\n",
    "\n",
    "    for _, row in evaluation_results.iterrows():\n",
    "        score = row['scores']\n",
    "        mrr = [1/(i+1) for i, s in enumerate(score) if s == 1]\n",
    "        mrr = mrr[0] if len(mrr) > 0 else 0\n",
    "        scores.append(mrr)\n",
    "    return round(np.mean(scores), 4)\n",
    "\n",
    "def compute_all_metrics(evaluation_results: pd.DataFrame) -> pd.DataFrame:\n",
    "    models = []\n",
    "    precision_at_k = []\n",
    "    hit_rate = []\n",
    "    ndcg = []\n",
    "    mrr = []\n",
    "\n",
    "    for chunking_strategy in CHUNKING_STRATEGIES:\n",
    "        for embedding_model in EMBEDDING_MODELS:\n",
    "            model = f\"{chunking_strategy} + {embedding_model}\"\n",
    "            valid_df = evaluation_results[(evaluation_results['chunking_strategy'] == chunking_strategy) & (evaluation_results['embedding_model'] == embedding_model)]\n",
    "            models.append(model)\n",
    "            precision_at_k.append(compute_precision_at_k(valid_df))\n",
    "            hit_rate.append(compute_hit_rate(valid_df))\n",
    "            ndcg.append(compute_ndcg(valid_df))\n",
    "            mrr.append(compute_mrr(valid_df))\n",
    "\n",
    "    metrics_df = pd.DataFrame(\n",
    "        {\n",
    "            'Chunking Strategy + Embedding model': models,\n",
    "            'Precision@K': precision_at_k,\n",
    "            'HitRate': hit_rate,\n",
    "            'NDCG': ndcg,\n",
    "            'MRR': mrr\n",
    "        }\n",
    "    )\n",
    "\n",
    "    return metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Chunking Strategy + Embedding model</th>\n",
       "      <th>Precision@K</th>\n",
       "      <th>HitRate</th>\n",
       "      <th>NDCG</th>\n",
       "      <th>MRR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fixed-size-splitter + all-MiniLM-L6-v2</td>\n",
       "      <td>0.4337</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.4813</td>\n",
       "      <td>0.7907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fixed-size-splitter + bert-base-nli-mean-tokens</td>\n",
       "      <td>0.3979</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.4392</td>\n",
       "      <td>0.7095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fixed-size-splitter + gtr-t5-base</td>\n",
       "      <td>0.3863</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.4410</td>\n",
       "      <td>0.7893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>recursive-splitter + all-MiniLM-L6-v2</td>\n",
       "      <td>0.3919</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.4401</td>\n",
       "      <td>0.7655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>recursive-splitter + bert-base-nli-mean-tokens</td>\n",
       "      <td>0.3964</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.4407</td>\n",
       "      <td>0.7345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>recursive-splitter + gtr-t5-base</td>\n",
       "      <td>0.4120</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.4560</td>\n",
       "      <td>0.7756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>semantic-splitter + all-MiniLM-L6-v2</td>\n",
       "      <td>0.4293</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.4679</td>\n",
       "      <td>0.7532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>semantic-splitter + bert-base-nli-mean-tokens</td>\n",
       "      <td>0.4177</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.4568</td>\n",
       "      <td>0.7340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>semantic-splitter + gtr-t5-base</td>\n",
       "      <td>0.4132</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.4589</td>\n",
       "      <td>0.7739</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Chunking Strategy + Embedding model  Precision@K  HitRate  \\\n",
       "0           fixed-size-splitter + all-MiniLM-L6-v2       0.4337     0.91   \n",
       "1  fixed-size-splitter + bert-base-nli-mean-tokens       0.3979     0.86   \n",
       "2                fixed-size-splitter + gtr-t5-base       0.3863     0.91   \n",
       "3            recursive-splitter + all-MiniLM-L6-v2       0.3919     0.86   \n",
       "4   recursive-splitter + bert-base-nli-mean-tokens       0.3964     0.91   \n",
       "5                 recursive-splitter + gtr-t5-base       0.4120     0.94   \n",
       "6             semantic-splitter + all-MiniLM-L6-v2       0.4293     0.91   \n",
       "7    semantic-splitter + bert-base-nli-mean-tokens       0.4177     0.91   \n",
       "8                  semantic-splitter + gtr-t5-base       0.4132     0.91   \n",
       "\n",
       "     NDCG     MRR  \n",
       "0  0.4813  0.7907  \n",
       "1  0.4392  0.7095  \n",
       "2  0.4410  0.7893  \n",
       "3  0.4401  0.7655  \n",
       "4  0.4407  0.7345  \n",
       "5  0.4560  0.7756  \n",
       "6  0.4679  0.7532  \n",
       "7  0.4568  0.7340  \n",
       "8  0.4589  0.7739  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_results = pd.read_csv('retrieval_validation/gpt_evaluations_hybrid_search.csv')\n",
    "evaluation_results['scores'] = evaluation_results['scores'].apply(lambda score: list(map(int, ast.literal_eval(score))))\n",
    "metrics = compute_all_metrics(evaluation_results)\n",
    "\n",
    "metrics.to_csv('retrieval_validation/metrics_hybrid_search.csv', index=False)\n",
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Chunking Strategy + Embedding model</th>\n",
       "      <th>Precision@K</th>\n",
       "      <th>HitRate</th>\n",
       "      <th>NDCG</th>\n",
       "      <th>MRR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fixed-size-splitter + all-MiniLM-L6-v2</td>\n",
       "      <td>0.3450</td>\n",
       "      <td>0.9400</td>\n",
       "      <td>0.3819</td>\n",
       "      <td>0.6874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fixed-size-splitter + bert-base-nli-mean-tokens</td>\n",
       "      <td>0.3000</td>\n",
       "      <td>0.8600</td>\n",
       "      <td>0.3255</td>\n",
       "      <td>0.5582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fixed-size-splitter + gtr-t5-base</td>\n",
       "      <td>0.3480</td>\n",
       "      <td>0.9500</td>\n",
       "      <td>0.3916</td>\n",
       "      <td>0.7128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>recursive-splitter + all-MiniLM-L6-v2</td>\n",
       "      <td>0.3320</td>\n",
       "      <td>0.9300</td>\n",
       "      <td>0.3716</td>\n",
       "      <td>0.6805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>recursive-splitter + bert-base-nli-mean-tokens</td>\n",
       "      <td>0.3000</td>\n",
       "      <td>0.8300</td>\n",
       "      <td>0.3222</td>\n",
       "      <td>0.5478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>recursive-splitter + gtr-t5-base</td>\n",
       "      <td>0.3323</td>\n",
       "      <td>0.9091</td>\n",
       "      <td>0.3741</td>\n",
       "      <td>0.6760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>semantic-splitter + all-MiniLM-L6-v2</td>\n",
       "      <td>0.3313</td>\n",
       "      <td>0.9394</td>\n",
       "      <td>0.3650</td>\n",
       "      <td>0.6639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>semantic-splitter + bert-base-nli-mean-tokens</td>\n",
       "      <td>0.2768</td>\n",
       "      <td>0.8485</td>\n",
       "      <td>0.3102</td>\n",
       "      <td>0.5682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>semantic-splitter + gtr-t5-base</td>\n",
       "      <td>0.3333</td>\n",
       "      <td>0.9596</td>\n",
       "      <td>0.3709</td>\n",
       "      <td>0.6636</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Chunking Strategy + Embedding model  Precision@K  HitRate  \\\n",
       "0           fixed-size-splitter + all-MiniLM-L6-v2       0.3450   0.9400   \n",
       "1  fixed-size-splitter + bert-base-nli-mean-tokens       0.3000   0.8600   \n",
       "2                fixed-size-splitter + gtr-t5-base       0.3480   0.9500   \n",
       "3            recursive-splitter + all-MiniLM-L6-v2       0.3320   0.9300   \n",
       "4   recursive-splitter + bert-base-nli-mean-tokens       0.3000   0.8300   \n",
       "5                 recursive-splitter + gtr-t5-base       0.3323   0.9091   \n",
       "6             semantic-splitter + all-MiniLM-L6-v2       0.3313   0.9394   \n",
       "7    semantic-splitter + bert-base-nli-mean-tokens       0.2768   0.8485   \n",
       "8                  semantic-splitter + gtr-t5-base       0.3333   0.9596   \n",
       "\n",
       "     NDCG     MRR  \n",
       "0  0.3819  0.6874  \n",
       "1  0.3255  0.5582  \n",
       "2  0.3916  0.7128  \n",
       "3  0.3716  0.6805  \n",
       "4  0.3222  0.5478  \n",
       "5  0.3741  0.6760  \n",
       "6  0.3650  0.6639  \n",
       "7  0.3102  0.5682  \n",
       "8  0.3709  0.6636  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_results = pd.read_csv('retrieval_validation/gpt_evaluations_vector_search.csv')\n",
    "evaluation_results['scores'] = evaluation_results['scores'].apply(lambda score: list(map(int, ast.literal_eval(score))))\n",
    "\n",
    "metrics = compute_all_metrics(evaluation_results)\n",
    "metrics.to_csv('retrieval_validation/metrics_vector_search.csv', index=False)\n",
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
